{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pybaseball as pyb\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the excel file path that you wish to update\n",
    "excel_file_path = 'MLB Algorithm_2025 Season.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the injury report, parse it, then add it to the excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read in fangraphs injury report '''\n",
    "\n",
    "# URL of the injury report for the 2023 season\n",
    "url = 'https://www.fangraphs.com/roster-resource/injury-report?timeframe=all&season=2025'\n",
    "\n",
    "# Send a GET request to fetch the page content\n",
    "response = requests.get(url)\n",
    "#response.raise_for_status()  # Ensure the request was successful\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 229/229 [00:00<00:00, 1290988.73it/s]\n",
      "/home/jonnym/.local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/home/jonnym/.local/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 1: Load page\n",
    "url = 'https://www.fangraphs.com/roster-resource/injury-report?timeframe=all&season=2025'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 2: Find the script tag with the JSON data\n",
    "script_tag = soup.find('script', id='__NEXT_DATA__')\n",
    "\n",
    "# Step 3: Parse the JSON\n",
    "json_raw = script_tag.string\n",
    "data = json.loads(json_raw)\n",
    "res = []\n",
    "# Step 4: Navigate to the injury data\n",
    "injury_data = None\n",
    "queries = data['props']['pageProps']['dehydratedState']['queries']\n",
    "for q in queries:\n",
    "    if isinstance(q.get('state', {}).get('data'), list):\n",
    "        injury_data = q['state']['data']\n",
    "        break\n",
    "\n",
    "# Step 5: Use or print the injury data\n",
    "if injury_data:\n",
    "    for player in tqdm(injury_data):  # Preview first 5 entries\n",
    "        # print(player)\n",
    "        res.append({\n",
    "            'Player': player.get('playerName'),\n",
    "            'Team': player.get('team'),\n",
    "            'Pos': player.get('position'),\n",
    "            'Injury': player.get('injurySurgery'),\n",
    "            'Status': player.get('status'),\n",
    "            'Est. Return': player.get('returndate')\n",
    "        })\n",
    "else:\n",
    "    print(\"Injury data not found.\")\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(\"Fangraphs_Injury_Report.csv\")\n",
    "\n",
    "\n",
    "file_path = excel_file_path\n",
    "\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:            \n",
    "    df.to_excel(writer, sheet_name=\"Injury\", index=False, header=False)        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the daily lineup for rotowire, parse it, add to the excel sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url = \"https://www.rotowire.com/baseball/daily-lineups.php\"\n",
    "soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "\n",
    "data_pitiching = []\n",
    "data_batter = []\n",
    "team_type = ''\n",
    "\n",
    "for e in soup.select('.lineup__box ul li'):\n",
    "    if team_type != e.parent.get('class')[-1]:\n",
    "        order_count = 1\n",
    "        team_type = e.parent.get('class')[-1]\n",
    "\n",
    "    if e.get('class') and 'lineup__player-highlight' in e.get('class'):\n",
    "        data_pitiching.append({\n",
    "            'date': e.find_previous('main').get('data-gamedate'),\n",
    "            'game_time': e.find_previous('div', attrs={'class':'lineup__time'}).get_text(strip=True),\n",
    "            'pitcher_name':e.a.get_text(strip=True),\n",
    "            'team':e.find_previous('div', attrs={'class':team_type}).next.strip(),\n",
    "            'lineup_throws':e.span.get_text(strip=True)\n",
    "        })\n",
    "    elif e.get('class') and 'lineup__player' in e.get('class'):\n",
    "        data_batter.append({\n",
    "            'date': e.find_previous('main').get('data-gamedate'),\n",
    "            'game_time': e.find_previous('div', attrs={'class':'lineup__time'}).get_text(strip=True),\n",
    "            'batter_name':e.a.get_text(strip=True),\n",
    "            'team':e.find_previous('div', attrs={'class':team_type}).next.strip(),\n",
    "            'pos': e.div.get_text(strip=True),\n",
    "            'batting_order':order_count,\n",
    "            'lineup_bats':e.span.get_text(strip=True)\n",
    "        })\n",
    "        order_count+=1\n",
    "\n",
    "df_pitching = pd.DataFrame(data_pitiching)\n",
    "df_batter = pd.DataFrame(data_batter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_teams = {\n",
    "    \"Rockies\": \"COL\",\n",
    "    \"Red Sox\": \"BOS\",\n",
    "    \"Reds\": \"CIN\",\n",
    "    \"Royals\": \"KC\",\n",
    "    \"Diamondbacks\": \"ARI\",\n",
    "    \"Marlins\": \"MIA\",\n",
    "    \"Twins\": \"MIN\",\n",
    "    \"Yankees\": \"NYY\",\n",
    "    \"Angels\": \"LAA\",\n",
    "    \"Braves\": \"ATL\",\n",
    "    \"Nationals\": \"WSH\",\n",
    "    \"Cardinals\": \"STL\",\n",
    "    \"Phillies\": \"PHI\",\n",
    "    \"Pirates\": \"PIT\",\n",
    "    \"Astros\": \"HOU\",\n",
    "    \"Dodgers\": \"LAD\",\n",
    "    \"Rangers\": \"TEX\",\n",
    "    \"Blue Jays\": \"TOR\",\n",
    "    \"Orioles\": \"BAL\",\n",
    "    \"White Sox\": \"CWS\",\n",
    "    \"Padres\": \"SD\",\n",
    "    \"Tigers\": \"DET\",\n",
    "    \"Mets\": \"NYM\",\n",
    "    \"Guardians\": \"CLE\",\n",
    "    \"Brewers\": \"MIL\",\n",
    "    \"Cubs\": \"CHC\",\n",
    "    \"Giants\": \"SF\",\n",
    "    \"Mariners\": \"SEA\",\n",
    "    \"Athletics\": \"ATH\",\n",
    "    \"Rays\": \"TB\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = df_pitching.merge(df_batter,on=['team','date'],suffixes=(\"\",\"_x\"))\n",
    "combined = combined[combined.columns.drop(list(combined.filter(regex='_x')))]\n",
    "combined['team_short'] = combined['team'].apply(lambda x:mlb_teams[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now need to make it in the order that it is in the excel sheet\n",
    "\n",
    "combined = combined[['team_short','pitcher_name','batter_name','batting_order']]\n",
    "\n",
    "file_path = excel_file_path\n",
    "\n",
    "# Open the existing workbook\n",
    "wb = load_workbook(file_path)\n",
    "\n",
    "# Select the \"Lineups\" sheet\n",
    "ws = wb['Lineups']\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "for index, row in combined.iterrows():\n",
    "    # Assign values to columns O, P, Q, R (index starts at 2 to leave space for header)\n",
    "    ws[f'O{index + 2}'] = row['team_short']\n",
    "    ws[f'P{index + 2}'] = row['pitcher_name']\n",
    "    ws[f'Q{index + 2}'] = row['batter_name']\n",
    "    ws[f'R{index + 2}'] = row['batting_order']\n",
    "\n",
    "wb.save(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update the table with Streamers Data (projected Rest of Season) + pybaseball's fangraphs dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull in the streamers data and the fangraphs data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pybaseball as pyb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Batting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4189/4189 [00:00<00:00, 493191.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load page\n",
    "url = 'https://www.fangraphs.com/projections?pos=all&stats=bat&type=steameru'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 2: Find the script tag with the JSON data\n",
    "script_tag = soup.find('script', id='__NEXT_DATA__')\n",
    "\n",
    "# Step 3: Parse the JSON\n",
    "json_raw = script_tag.string\n",
    "data = json.loads(json_raw)\n",
    "res = []\n",
    "# Step 4: Navigate to the injury data\n",
    "streamers = None\n",
    "queries = data['props']['pageProps']['dehydratedState']['queries']\n",
    "for q in queries:\n",
    "    if isinstance(q.get('state', {}).get('data'), list):\n",
    "        streamers = q['state']['data']\n",
    "        break\n",
    "\n",
    "# Step 5: process the player data\n",
    "if streamers:\n",
    "    for player in tqdm(streamers):  # Preview first 5 entries\n",
    "        # print(player)\n",
    "        res.append({\n",
    "            'Player': player.get('PlayerName', 'NA'),\n",
    "            'Team': player.get('Team', 'NA'),\n",
    "            'Pos': player.get('minpos', 'NA'),  # using 'minpos' as positional name\n",
    "            'Age': player.get('Age', 'NA'),     # does not exist in sample\n",
    "            'G': player.get('G', 'NA'),\n",
    "            'AB': player.get('AB', 'NA'),\n",
    "            'R': player.get('R', 'NA'),\n",
    "            'H': player.get('H', 'NA'),\n",
    "            '2B': player.get('2B', 'NA'),\n",
    "            '3B': player.get('3B', 'NA'),\n",
    "            'HR': player.get('HR', 'NA'),\n",
    "            'RBI': player.get('RBI', 'NA'),\n",
    "            'SB': player.get('SB', 'NA'),\n",
    "            'CS': player.get('CS', 'NA'),\n",
    "            'BB': player.get('BB', 'NA'),\n",
    "            'SO': player.get('SO', 'NA'),\n",
    "            'SH': player.get('SH', 'NA'),\n",
    "            'SF': player.get('SF', 'NA'),\n",
    "            'HBP': player.get('HBP', 'NA'),\n",
    "            'AVG': player.get('AVG', 'NA'),\n",
    "            'OBP': player.get('OBP', 'NA'),\n",
    "            'SLG': player.get('SLG', 'NA'),\n",
    "            'OPS': player.get('OPS', 'NA'),\n",
    "            'Year': player.get('Year', 2025)   # does not exist in sample\n",
    "        })\n",
    "        \n",
    "else:\n",
    "    print(\"Streamers data not found in Fangraphs.\")\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(\"Fangraphs_Streamers_Data.csv\")\n",
    "\n",
    "df_batter = pyb.batting_stats(2025,qual=None)\n",
    "df_batter = df_batter[['Name','Team','Pos','Age','G','AB','R','H','2B','3B','HR','RBI','SB','CS','BB','SO','SH','SF','HBP','AVG','OBP','SLG','OPS','Season']]\n",
    "df_batter = df_batter.rename(columns={'Name':\"Player\",\"Season\":'Year'})\n",
    "\n",
    "\n",
    "# Need to do a function that gets the row of the streamers data for a given player, add their matching stats \n",
    "def combine_streamers_and_season_data(streamers_df, season_df):\n",
    "    combined_rows = []\n",
    "    \n",
    "    # Iterate through each row in the season stats\n",
    "    for _, season_row in season_df.iterrows():\n",
    "        player_name = season_row['Player']\n",
    "        \n",
    "        # Find matching player in streamers data\n",
    "        matching_streamer = streamers_df[streamers_df['Player'] == player_name]\n",
    "        \n",
    "        if not matching_streamer.empty:\n",
    "            streamer_row = matching_streamer.iloc[0]\n",
    "            \n",
    "            # Combine rows using your combine logic\n",
    "            combined = season_row.copy()\n",
    "            for col in season_row.index:\n",
    "                if col in streamer_row.index and col not in ['Player', 'Team', 'Pos', 'Age', 'Year']:\n",
    "                    try:\n",
    "                        combined[col] += streamer_row[col]\n",
    "                    except:\n",
    "                        combined[col] = 'NA'  # fallback in case of issues\n",
    "                        \n",
    "            # Recalculate rate stats\n",
    "            combined['AVG'] = combined['H'] / combined['AB'] # H/ AB\n",
    "            combined['OBP'] = (combined['H'] + combined['BB']) / (combined['AB'] + combined['BB'] - combined['SF'] - combined['SH']) # (H + BB) / (AB + BB - SF - SH)\n",
    "            tb_no_1b = (combined['2B']*2) + (combined['3B'] * 3) + (combined['HR'] * 4) # Total Bases w/o Singles\n",
    "            singles = combined['H'] - (combined['2B'] + combined['3B']+ combined['HR'])\n",
    "            tb = tb_no_1b + singles\n",
    "            combined['SLG'] = tb / combined['AB'] # tb / ab\n",
    "            combined['OPS'] = combined['OBP'] + combined['SLG']\n",
    "            combined['Pos'] = streamers_df['Pos']\n",
    "            \n",
    "            combined_rows.append(combined)\n",
    "        else:\n",
    "            # No matching streamer data, keep season data only\n",
    "            combined_rows.append(season_row)\n",
    "    \n",
    "    # Create combined DataFrame\n",
    "    return pd.DataFrame(combined_rows)\n",
    "\n",
    "# Usage:\n",
    "combined_data = combine_streamers_and_season_data(df, df_batter)\n",
    "\n",
    "\n",
    "file_path = excel_file_path\n",
    "\n",
    "# Open the existing workbook\n",
    "wb = load_workbook(file_path)\n",
    "ws =  wb['Batters']\n",
    "\n",
    "for index, row in combined_data.iterrows():\n",
    "    row_num = index + 3  # Start on row 2 to leave space for header\n",
    "\n",
    "    ws[f'E{row_num}'] = row['Player']\n",
    "    ws[f'F{row_num}'] = row['Team']\n",
    "    ws[f'G{row_num}'] = str(row['Pos'])\n",
    "    ws[f'H{row_num}'] = row['Age']\n",
    "    ws[f'I{row_num}'] = row['G']\n",
    "    ws[f'J{row_num}'] = row['AB']\n",
    "    ws[f'K{row_num}'] = row['R']\n",
    "    ws[f'L{row_num}'] = row['H']\n",
    "    ws[f'M{row_num}'] = row['2B']\n",
    "    ws[f'N{row_num}'] = row['3B']\n",
    "    ws[f'O{row_num}'] = row['HR']\n",
    "    ws[f'P{row_num}'] = row['RBI']\n",
    "    ws[f'Q{row_num}'] = row['SB']\n",
    "    ws[f'R{row_num}'] = row['CS']\n",
    "    ws[f'S{row_num}'] = row['BB']\n",
    "    ws[f'T{row_num}'] = row['SO']\n",
    "    ws[f'U{row_num}'] = row['SH']\n",
    "    ws[f'V{row_num}'] = row['SF']\n",
    "    ws[f'W{row_num}'] = row['HBP']\n",
    "    ws[f'X{row_num}'] = row['AVG']\n",
    "    ws[f'Y{row_num}'] = row['OBP']\n",
    "    ws[f'Z{row_num}'] = row['SLG']\n",
    "    ws[f'AA{row_num}'] = row['OPS']\n",
    "    ws[f'AB{row_num}'] = row['Year']\n",
    "\n",
    "wb.save(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Getting Piching Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5237/5237 [00:00<00:00, 449267.16it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Load page\n",
    "url = 'https://www.fangraphs.com/projections?type=steameru&stats=pit&pos=&team=0&players=0&lg=all&z=1744628169&sortcol=&sortdir=desc&pageitems=30&statgroup=dashboard&fantasypreset=dashboard'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Step 2: Find the script tag with the JSON data\n",
    "script_tag = soup.find('script', id='__NEXT_DATA__')\n",
    "\n",
    "# Step 3: Parse the JSON\n",
    "json_raw = script_tag.string\n",
    "data = json.loads(json_raw)\n",
    "res = []\n",
    "# Step 4: Navigate to the injury data\n",
    "streamers = None\n",
    "queries = data['props']['pageProps']['dehydratedState']['queries']\n",
    "for q in queries:\n",
    "    if isinstance(q.get('state', {}).get('data'), list):\n",
    "        streamers = q['state']['data']\n",
    "        break\n",
    "\n",
    "# Step 5: process the player data\n",
    "if streamers:\n",
    "    for player in tqdm(streamers):  # Preview first 5 entries\n",
    "        # print(player)\n",
    "        res.append({\n",
    "            'Player': player.get('PlayerName', 'NA'),\n",
    "            'Team': player.get('Team', 'NA'),\n",
    "            'Age': 'NA',  # Not available\n",
    "            'G': player.get('G', 'NA'),\n",
    "            'GS': player.get('GS', 'NA'),\n",
    "            'CG': 'NA',  # Not available\n",
    "            'ShO': 'NA',  # Not available\n",
    "            'IP': player.get('IP', 'NA'),\n",
    "            'H': player.get('H', 'NA'),\n",
    "            'ER': player.get('ER', 'NA'),\n",
    "            'SO': player.get('SO', 'NA'),  # Note: 'SO' is K\n",
    "            'BB': player.get('BB', 'NA'),\n",
    "            'HR': player.get('HR', 'NA'),\n",
    "            'W': player.get('W', 'NA'),\n",
    "            'L': player.get('L', 'NA'),\n",
    "            'SV': player.get('SV', 'NA'),\n",
    "            'BS': player.get('BS', 'NA'),\n",
    "            'HLD': player.get('HLD', 'NA'),\n",
    "            'ERA': player.get('ERA', 'NA'),\n",
    "            'WHIP': player.get('WHIP', 'NA'),\n",
    "            'Year': 2025,\n",
    "            'IP per GS': player.get('IP', 0) / player.get('GS', 1) if player.get('GS', 1) != 0 else 0\n",
    "    })\n",
    "        \n",
    "else:\n",
    "    print(\"Streamers data not found in Fangraphs.\")\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.to_csv(\"Fangraphs_Streamers_Data.csv\")\n",
    "\n",
    "df_pitcher = pyb.pitching_stats(2025, qual=None)\n",
    "df_pitcher = df_pitcher[['Name','Team','Age','G','GS','CG','ShO','IP','H','ER','SO','BB','HR','W','L','SV','BS','HLD','ERA','WHIP','Season']]\n",
    "df_pitcher['IP per GS'] = df_pitcher['IP'] / df_pitcher['GS'].replace(0, pd.NA)\n",
    "df_pitcher = df_pitcher.rename(columns={'Name':\"Player\",\"Season\":'Year'})\n",
    "\n",
    "\n",
    "# Need to do a function that gets the row of the streamers data for a given player, add their matching stats \n",
    "def combine_pitcher_data(streamers_df, season_df):\n",
    "    combined_rows = []\n",
    "\n",
    "    for idx, season_row in season_df.iterrows():\n",
    "        player_name = season_row['Player']\n",
    "        match = streamers_df[streamers_df['Player'] == player_name]\n",
    "\n",
    "        if not match.empty:\n",
    "            stream_row = match.iloc[0]\n",
    "            combined = season_row.copy()\n",
    "\n",
    "            for col in season_row.index:\n",
    "                if col in stream_row.index and col not in ['Player', 'Team', 'Age', 'Year', 'IP per GS']:\n",
    "                    try:\n",
    "                        combined[col] += stream_row[col]\n",
    "                    except:\n",
    "                        combined[col] = 'NA'\n",
    "\n",
    "            # Recalculate derived stat\n",
    "            combined['IP per GS'] = combined['IP'] / combined['GS'] if combined['GS'] else 0\n",
    "            combined['ERA'] = (combined['ER'] / combined['IP']) * 9\n",
    "            combined['WHIP'] = (combined['BB'] + combined['H']) / combined['IP']\n",
    "\n",
    "            combined_rows.append(combined)\n",
    "        else:\n",
    "            combined_rows.append(season_row)\n",
    "\n",
    "    return pd.DataFrame(combined_rows)\n",
    "\n",
    "# Usage:\n",
    "combined = combine_pitcher_data(df, df_pitcher)\n",
    "\n",
    "\n",
    "file_path = excel_file_path\n",
    "\n",
    "wb = load_workbook(file_path)\n",
    "\n",
    "ws = wb['Pitchers']\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "\n",
    "for index, row in combined.iterrows():\n",
    "    row_num = index + 2  # Start on row 2 to leave space for header\n",
    "    \n",
    "    ws[f'B{row_num}'] = row['Player']\n",
    "    ws[f'C{row_num}'] = row['Team']\n",
    "    ws[f'D{row_num}'] = row['Age']\n",
    "    ws[f'E{row_num}'] = row['G']\n",
    "    ws[f'F{row_num}'] = row['GS']\n",
    "    ws[f'G{row_num}'] = row['CG']\n",
    "    ws[f'H{row_num}'] = row['ShO']\n",
    "    ws[f'I{row_num}'] = row['IP']\n",
    "    ws[f'J{row_num}'] = row['H']\n",
    "    ws[f'K{row_num}'] = row['ER']\n",
    "    ws[f'L{row_num}'] = row['SO']\n",
    "    ws[f'M{row_num}'] = row['BB']\n",
    "    ws[f'N{row_num}'] = row['HR']\n",
    "    ws[f'O{row_num}'] = row['W']\n",
    "    ws[f'P{row_num}'] = row['L']\n",
    "    ws[f'Q{row_num}'] = row['SV']\n",
    "    ws[f'R{row_num}'] = row['BS']\n",
    "    ws[f'S{row_num}'] = row['HLD']\n",
    "    ws[f'T{row_num}'] = row['ERA']\n",
    "    ws[f'U{row_num}'] = row['WHIP']\n",
    "    ws[f'V{row_num}'] = row['Year']\n",
    "    ws[f'W{row_num}'] = row['IP per GS']\n",
    "\n",
    "wb.save(file_path)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_path = excel_file_path\n",
    "\n",
    "wb = load_workbook(file_path)\n",
    "\n",
    "ws = wb['Pitchers']\n",
    "\n",
    "# Iterate over the rows of the DataFrame\n",
    "\n",
    "for index, row in combined.iterrows():\n",
    "    row_num = index + 2  # Start on row 2 to leave space for header\n",
    "    \n",
    "    ws[f'B{row_num}'] = row['Player']\n",
    "    ws[f'C{row_num}'] = row['Team']\n",
    "    ws[f'D{row_num}'] = row['Age']\n",
    "    ws[f'E{row_num}'] = row['G']\n",
    "    ws[f'F{row_num}'] = row['GS']\n",
    "    ws[f'G{row_num}'] = row['CG']\n",
    "    ws[f'H{row_num}'] = row['ShO']\n",
    "    ws[f'I{row_num}'] = row['IP']\n",
    "    ws[f'J{row_num}'] = row['H']\n",
    "    ws[f'K{row_num}'] = row['ER']\n",
    "    ws[f'L{row_num}'] = row['SO']\n",
    "    ws[f'M{row_num}'] = row['BB']\n",
    "    ws[f'N{row_num}'] = row['HR']\n",
    "    ws[f'O{row_num}'] = row['W']\n",
    "    ws[f'P{row_num}'] = row['L']\n",
    "    ws[f'Q{row_num}'] = row['SV']\n",
    "    ws[f'R{row_num}'] = row['BS']\n",
    "    ws[f'S{row_num}'] = row['HLD']\n",
    "    ws[f'T{row_num}'] = row['ERA']\n",
    "    ws[f'U{row_num}'] = row['WHIP']\n",
    "    ws[f'V{row_num}'] = row['Year']\n",
    "    ws[f'W{row_num}'] = row['IP per GS']\n",
    "\n",
    "wb.save(file_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
